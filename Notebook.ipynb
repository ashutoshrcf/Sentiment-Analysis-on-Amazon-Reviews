{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product Review System Using Feedback Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import math\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore') \n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "df = pd.read_csv(\"Reviews_Data.csv\")\n",
    "del df[\"reviews.userCity\"], df[\"reviews.userProvince\"], df[\"reviews.username\"], df[\"reviews.id\"], df[\"reviews.didPurchase\"]\n",
    "data = df.copy()\n",
    "\n",
    "dataAfter = data.dropna(subset=[\"reviews.rating\"]) # Removes all NAN in reviews.rating\n",
    "dataAfter[\"reviews.rating\"] = dataAfter[\"reviews.rating\"].astype(int) # typecasting reviews.ratings string -> int\n",
    " \n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "split = StratifiedShuffleSplit(n_splits=5, test_size=0.2) # Train/Test Split 4:1\n",
    "for train_index, test_index in split.split(dataAfter, dataAfter[\"reviews.rating\"]): \n",
    "    strat_train = dataAfter.reindex(train_index)\n",
    "    strat_test = dataAfter.reindex(test_index)\n",
    "\n",
    "def sentiments(rating): # Sentiments to applied / Target Variable\n",
    "    if (rating == 5) or (rating == 4):\n",
    "        return \"Positive\"\n",
    "    elif rating == 3:\n",
    "        return \"Neutral\"\n",
    "    elif (rating == 2) or (rating == 1):\n",
    "        return \"Negative\"\n",
    "    \n",
    "# Applying sentiments to the reviews.rating\n",
    "strat_train[\"Sentiment\"] = strat_train[\"reviews.rating\"].apply(sentiments)\n",
    "strat_test[\"Sentiment\"] = strat_test[\"reviews.rating\"].apply(sentiments)\n",
    "\n",
    "X_train = strat_train[\"reviews.text\"]\n",
    "X_train_targetSentiment = strat_train[\"Sentiment\"]\n",
    "X_test = strat_test[\"reviews.text\"]\n",
    "X_test_targetSentiment = strat_test[\"Sentiment\"]\n",
    "\n",
    "# Replace \"nan\" with space\n",
    "X_train = X_train.fillna(' ')\n",
    "X_test = X_test.fillna(' ')\n",
    "X_train_targetSentiment = X_train_targetSentiment.fillna(' ')\n",
    "X_test_targetSentiment = X_test_targetSentiment.fillna(' ')\n",
    "\n",
    "# Text preprocessing and occurance counting\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train) \n",
    "\n",
    "# Applying TF-Idf \n",
    "tfidf_transformer = TfidfTransformer(use_idf=False)\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinominal Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "93.43055154490327"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "clf_multiNB_pipe = Pipeline([(\"vect\", CountVectorizer()), \n",
    "                             (\"tfidf\", TfidfTransformer()),\n",
    "                             (\"clf_nominalNB\", MultinomialNB())])\n",
    "clf_multiNB_pipe.fit(X_train, X_train_targetSentiment)\n",
    "\n",
    "predictedMultiNB = clf_multiNB_pipe.predict(X_test)\n",
    "np.mean(predictedMultiNB == X_test_targetSentiment)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "93.83482529598614"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "clf_linearSVC_pipe = Pipeline([(\"vector\", CountVectorizer()), \n",
    "                               (\"tfidf\", TfidfTransformer()),\n",
    "                               (\"linearSVC\", LinearSVC())])\n",
    "clf_linearSVC_pipe.fit(X_train, X_train_targetSentiment)\n",
    "\n",
    "predictedLinearSVC = clf_linearSVC_pipe.predict(X_test)\n",
    "np.mean(predictedLinearSVC == X_test_targetSentiment)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "93.80594859948022"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "clf_logReg_pipe = Pipeline([(\"vect\", CountVectorizer()), \n",
    "                            (\"tfidf\", TfidfTransformer()), \n",
    "                            (\"clf_logReg\", LogisticRegression())])\n",
    "clf_logReg_pipe.fit(X_train, X_train_targetSentiment)\n",
    "\n",
    "import numpy as np\n",
    "predictedLogReg = clf_logReg_pipe.predict(X_test)\n",
    "np.mean(predictedLogReg == X_test_targetSentiment)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "89.8931562229281"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf_decisionTree_pipe = Pipeline([(\"vect\", CountVectorizer()), \n",
    "                                  (\"tfidf\", TfidfTransformer()), \n",
    "                                  (\"clf_decisionTree\", DecisionTreeClassifier())\n",
    "                                 ])\n",
    "clf_decisionTree_pipe.fit(X_train, X_train_targetSentiment)\n",
    "\n",
    "predictedDecisionTree = clf_decisionTree_pipe.predict(X_test)\n",
    "np.mean(predictedDecisionTree == X_test_targetSentiment)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "93.4883049379151"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_randomForest_pipe = Pipeline([(\"vect\", CountVectorizer()), \n",
    "                                  (\"tfidf\", TfidfTransformer()), \n",
    "                                  (\"clf_randomForest\", RandomForestClassifier())\n",
    "                                 ])\n",
    "clf_randomForest_pipe.fit(X_train, X_train_targetSentiment)\n",
    "\n",
    "predictedRandomForest = clf_randomForest_pipe.predict(X_test)\n",
    "np.mean(predictedRandomForest == X_test_targetSentiment)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MNB Classifier \n--------------           0\n0  Positive\n1  Positive\n2  Positive\n\n\nLinear SVC \n--------------           0\n0  Positive\n1   Neutral\n2   Neutral\n\n\nLogistic Regression \n--------------           0\n0  Positive\n1   Neutral\n2   Neutral\n\n\nDecesion Tree \n--------------           0\n0  Negative\n1  Positive\n2   Neutral\n\n\nRandom Forest \n--------------           0\n0  Positive\n1  Positive\n2  Positive\n\n\n"
     ]
    }
   ],
   "source": [
    "testing_data = [\"The tablet is good, really liked it.\",\n",
    "            \"The tablet is ok, and it works fine.\", \n",
    "            \"The tablet is not good and does not work.\"]\n",
    "\n",
    "pipe_list = [clf_multiNB_pipe,clf_linearSVC_pipe,clf_logReg_pipe,clf_decisionTree_pipe,clf_randomForest_pipe]\n",
    "pipe_names = [\"MNB Classifier\",\"Linear SVC\", \"Logistic Regression\", \"Decesion Tree\", \"Random Forest\"]\n",
    "for name, model in zip(pipe_names,pipe_list):\n",
    "    print(name,\"\\n--------------\",pd.DataFrame(model.predict(testing_data)))\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}